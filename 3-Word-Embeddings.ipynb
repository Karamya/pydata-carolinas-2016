{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a vocabulary of words that we are working with. We want to represent each word as a vector, so that we can use it in a network. One way we could do this is by using **one-hot encoding**. Each word is represented as a vector of all zeros, except for the index corresponding to that word, which is represented as a 1. This means that each sentence is represented by a matrix with dimensions `<nb_words, nb_vocab>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      "{'brown': 4, 'the': 0, 'jumped': 6, 'over': 1, 'lazy': 2, 'dog': 5, 'fox': 3}\n",
      "\n",
      "One-hot encoded:\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sentence = ['the', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']\n",
    "vocabulary = dict([(word, i) for i, word in enumerate(set(sentence))])\n",
    "print('Vocabulary:')\n",
    "print(vocabulary, end='\\n\\n')\n",
    "\n",
    "def one_hot_encode(sentence):\n",
    "    ohe = np.zeros((len(sentence), len(vocabulary)))\n",
    "    for i, word in enumerate(sentence):\n",
    "        ohe[i, vocabulary[word]] = 1\n",
    "    return ohe\n",
    "\n",
    "print('One-hot encoded:')\n",
    "print(one_hot_encode(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obvious problem is that this scales horribly! If we have 10000 words in our vocabulary, then we are representing each word with 9999 zeros and a single 1! On top of that, the vectors don't tell us anything about how the words are related. A better way is to use **word embeddings**.\n",
    "\n",
    "There are different ways of generating word embeddings. In general, word embeddings are just a vector representation of words which hopefully conveys something about their meaning, for example:\n",
    "\n",
    "`king - man + woman = queen`\n",
    "\n",
    "Two popular methods for generating word embeddings are **word2vec** and **GloVe**. Let's try generating some word embeddings using Keras!\n",
    "\n",
    "First, we will generate some testing data. For this example, let's try to match a name with a color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sam is red -> [0]\n",
      "hannah not red -> [1]\n",
      "hannah is green -> [1]\n",
      "bob is green -> [1]\n",
      "bob not red -> [1]\n",
      "sam not green -> [0]\n",
      "sarah is red -> [0]\n",
      "sarah not green -> [0]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "sentences = '''\n",
    "sam is red\n",
    "hannah not red\n",
    "hannah is green\n",
    "bob is green\n",
    "bob not red\n",
    "sam not green\n",
    "sarah is red\n",
    "sarah not green'''.strip().split('\\n')\n",
    "is_green = np.asarray([[0, 1, 1, 1, 1, 0, 0, 0]], dtype='int32').T\n",
    "\n",
    "for s, g in zip(sentences, is_green):\n",
    "    print(s, '->', g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's **tokenize** the sentences to get individual words, then generate our vocabulary and convert our sentences from words to indices. The difference here is that we can represent each word as a single integer, rather than a sparse vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      "{'not': 4, 'red': 0, 'sam': 5, 'sarah': 6, 'hannah': 1, 'bob': 2, 'is': 3, 'green': 7}\n",
      "\n",
      "Sentences:\n",
      "[[5 3 0]\n",
      " [1 4 0]\n",
      " [1 3 7]\n",
      " [2 3 7]\n",
      " [2 4 0]\n",
      " [5 4 7]\n",
      " [6 3 0]\n",
      " [6 4 7]]\n"
     ]
    }
   ],
   "source": [
    "tokenize = lambda x: x.strip().lower().split(' ')\n",
    "sentences_tokenized = [tokenize(sentence) for sentence in sentences]\n",
    "words = set(itertools.chain(*sentences_tokenized))\n",
    "\n",
    "word2idx = dict((v, i) for i, v in enumerate(words))\n",
    "idx2word = list(words)\n",
    "print('Vocabulary:')\n",
    "print(word2idx, end='\\n\\n')\n",
    "\n",
    "to_idx = lambda x: [word2idx[word] for word in x] # convert a list of words to a list of indices\n",
    "sentences_idx = [to_idx(sentence) for sentence in sentences_tokenized]\n",
    "sentences_array = np.asarray(sentences_idx, dtype='int32')\n",
    "print('Sentences:')\n",
    "print(sentences_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's some parameters for our model. I chose to embed each word into a two-dimensional vector space, because that is easily visualized. For a vocabulary with around 20,000 words, it is common to use embeddings of around 100 to 200 dimensions, although this varies greatly by application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 words per sentence, 8 in vocabulary, 2 dimensions for embedding\n"
     ]
    }
   ],
   "source": [
    "sentence_maxlen = 3\n",
    "n_words = len(words)\n",
    "n_embed_dims = 2\n",
    "print('%d words per sentence, %d in vocabulary, %d dimensions for embedding' % (sentence_maxlen, n_words, n_embed_dims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's put together our model in Keras. It takes as inputs a list of indices at integers, then embeds them in a `n_embed_dims`-dimensional space, and then feeds them to a neural network which predicts what color they refer to (don't worry about that part too much)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, merge, Flatten, Reshape, Lambda\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "\n",
    "input_sentence = Input(shape=(sentence_maxlen,), dtype='int32')\n",
    "input_embedding = Embedding(n_words, n_embed_dims)(input_sentence)\n",
    "avepool = Lambda(lambda x: K.mean(x, axis=1, keepdims=True), output_shape=lambda x: (x[0], 1))\n",
    "color_prediction = avepool(Reshape((sentence_maxlen * n_embed_dims,))(input_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's fit the model. In Keras, we can easily specify that we want to use binary crossentropy for our loss function; no need to look up it's formula on Wikipedia!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red: [ 0.61401689  0.61265367]\n",
      "hannah: [ 1.8019402   1.76513004]\n",
      "bob: [ 1.79619455  1.78687334]\n",
      "is: [ 0.58042651  0.62761694]\n",
      "not: [ 0.62960142  0.57741958]\n",
      "sam: [-1.18396139 -1.25097883]\n",
      "sarah: [-1.21701324 -1.21796882]\n",
      "green: [ 0.64664161  0.57983446]\n"
     ]
    }
   ],
   "source": [
    "predict_green = Model(input=[input_sentence], output=[color_prediction])\n",
    "predict_green.compile(optimizer='sgd', loss='binary_crossentropy')\n",
    "\n",
    "predict_green.fit([sentences_array], [is_green], nb_epoch=5000, verbose=0)\n",
    "embeddings = predict_green.layers[1].W.get_value()\n",
    "\n",
    "for i in range(n_words):\n",
    "    print('{}: {}'.format(idx2word[i], embeddings[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Awesome! Let's plot our results in 3-dimensional space to see what kind of embeddings we learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAFdCAYAAAANJWRbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACHIfwBAHAYwh8AAIch/AEAcJj/BzJ5UFOURDM0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d89df60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "x1, x2 = embeddings[:, 0], embeddings[:, 1]\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "offsets_x = [random.randint(0, 1) * 0.6 - 0.3 for _ in range(n_words)]\n",
    "offsets_y = [random.randint(0, 1) * 0.6 - 0.3 for _ in range(n_words)]\n",
    "for i, ox, oy in zip(range(n_words), offsets_x, offsets_y):\n",
    "    ax.plot(x1[i], x2[i], 'o', color='black')\n",
    "    ax.annotate(idx2word[i], xy=[x1[i], x2[i]], xytext=[x1[i] + ox, x2[i] + oy])\n",
    "\n",
    "ax.set_xlim(min(x1)-1, max(x1)+1)\n",
    "ax.set_ylim(min(x2)-1, max(x2)+1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If it worked the way I expected it to work, you should see Bob and Hannah (who were both green) together in one corner, and Sarah and Sam (who were both red) together in another corner, with the other parts floating in the middle. The network didn't learn anything unique about \"not\" or \"is\" or \"green\" or \"red\" because it those are higher-order correlations, and it is a simple linear model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
